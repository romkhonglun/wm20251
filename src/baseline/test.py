import sys
import os
import argparse
import numpy as np
import torch
import polars as pl
import pyarrow.parquet as pq
from tqdm import tqdm
import zipfile
from torch.utils.data import DataLoader, IterableDataset
from torch.nn.utils.rnn import pad_sequence

# ThÃªm Ä‘Æ°á»ng dáº«n hiá»‡n táº¡i vÃ o sys.path Ä‘á»ƒ import cÃ¡c module cÃ¹ng thÆ° má»¥c
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import trá»±c tiáº¿p tá»« cÃ¡c file trong cÃ¹ng thÆ° má»¥c baseline
from lightning_module import NAMLLightningModule
from model import VariantNAMLConfig
from dataset import CompactHistory


# --- HÃ€M Há»– TRá»¢ ---
def calculate_ranks(scores):
    """Chuyá»ƒn Ä‘á»•i scores thÃ nh ranks (1 = score cao nháº¥t)."""
    scores = np.array(scores)
    # Láº¥y indices Ä‘á»ƒ sort giáº£m dáº§n
    indices_desc = np.argsort(-scores)
    # Táº¡o máº£ng rank
    ranks = np.empty_like(indices_desc)
    # GÃ¡n rank: rank 1 cho pháº§n tá»­ lá»›n nháº¥t
    ranks[indices_desc] = np.arange(len(scores)) + 1
    return ranks.tolist()


def write_submission(predictions, output_path):
    print(f"ğŸ“¦ Äang nÃ©n file submission vÃ o: {output_path}")
    lines = []
    for imp_id, ranks in predictions:
        # Format: impression_id [rank1,rank2,rank3]
        rank_str = "[" + ",".join(map(str, ranks)) + "]"
        lines.append(f"{imp_id} {rank_str}")

    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("predictions.txt", "\n".join(lines))
    print("âœ… ÄÃ£ táº¡o file submission thÃ nh cÃ´ng!")


# --- DATASET CHO TEST ---
class BaselineTestDataset(IterableDataset):
    def __init__(self, behaviors_path, compact_history, max_hist_len=50):
        self.behaviors_path = behaviors_path
        self.compact_history = compact_history
        self.max_hist_len = max_hist_len

    def __iter__(self):
        pf = pq.ParquetFile(self.behaviors_path)
        # Äá»c tá»«ng batch lá»›n Ä‘á»ƒ tá»‘i Æ°u I/O
        for batch in pf.iter_batches(batch_size=4096):
            df = pl.from_arrow(batch)

            # Xá»­ lÃ½ tÃªn cá»™t (Test set gá»‘c thÆ°á»ng lÃ  'article_ids_inview')
            inv_col = 'article_ids_inview' if 'article_ids_inview' in df.columns else 'inv_ids'

            # Kiá»ƒm tra impression_id
            if 'impression_id' not in df.columns:
                print("âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y cá»™t 'impression_id'. Sáº½ dÃ¹ng dummy ID.")
                imp_ids = [0] * len(df)
            else:
                imp_ids = df['impression_id'].to_list()

            user_ids = df['user_id'].to_list()
            inv_lists = df[inv_col].to_list()

            for i in range(len(df)):
                hist_ids = self.compact_history.get_history(user_ids[i])
                yield {
                    "impression_id": imp_ids[i],
                    "hist_ids": hist_ids[:self.max_hist_len],
                    "candidate_ids": np.array(inv_lists[i], dtype=np.int32),
                }


def collate_fn_test(batch):
    imp_ids = [item['impression_id'] for item in batch]
    hist_ids = [torch.from_numpy(item['hist_ids']).long() for item in batch]
    cands = [torch.from_numpy(item['candidate_ids']).long() for item in batch]

    # Pad history vÃ  candidates
    hist_padded = pad_sequence(hist_ids, batch_first=True, padding_value=0)
    cands_padded = pad_sequence(cands, batch_first=True, padding_value=0)

    return {
        "impression_ids": imp_ids,
        "hist_ids": hist_padded,
        "candidate_ids": cands_padded,
        "cand_lens": [len(c) for c in cands]  # LÆ°u Ä‘á»™ dÃ i tháº­t Ä‘á»ƒ cáº¯t rank sau nÃ y
    }


# --- MAIN ---
def main():
    parser = argparse.ArgumentParser(description="Test Script for Baseline")
    parser.add_argument("--checkpoint", type=str, required=True, help="Path tá»›i file .ckpt")
    parser.add_argument("--test-dir", type=str, required=True,
                        help="Folder chá»©a behaviors.parquet vÃ  history.parquet cá»§a táº­p test")
    parser.add_argument("--embedding-dir", type=str, default="/home2/congnh/wm/embedding_test",
                        help="Folder chá»©a embedding npy")
    parser.add_argument("--output", type=str, default="submission_baseline.zip")
    parser.add_argument("--batch-size", type=int, default=32)
    args = parser.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. Load Model
    print("ğŸ”„ Äang load model Baseline...")
    model = NAMLLightningModule.load_from_checkpoint(
        args.checkpoint,
        config=VariantNAMLConfig(),
        embedding_dir=args.embedding_dir,
        map_location=device
    )
    model.eval()
    model.to(device)

    # 2. Load Data
    # LÆ°u Ã½: Náº¿u tÃªn file khÃ¡c (vÃ­ dá»¥ behaviors_processed.parquet), hÃ£y sá»­a láº¡i á»Ÿ Ä‘Ã¢y
    beh_path = os.path.join(args.test_dir,"test", "behaviors_processed.parquet")
    hist_path = os.path.join(args.test_dir,"test", "history_processed.parquet")

    print(f"ğŸ“š Äang load History tá»« {hist_path}...")
    compact_hist = CompactHistory(hist_path)
    print(f"ğŸ“š Äang load Behaviors tá»« {beh_path}...")
    dataset = BaselineTestDataset(beh_path, compact_hist)
    dataloader = DataLoader(dataset, batch_size=args.batch_size, collate_fn=collate_fn_test)

    # 3. Inference
    predictions = []
    print("ğŸš€ Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n...")
    with torch.no_grad():
        for batch in tqdm(dataloader):
            # Move data to GPU
            model_input = {
                "hist_ids": batch["hist_ids"].to(device),
                "candidate_ids": batch["candidate_ids"].to(device),
                "labels": None  # Test khÃ´ng cáº§n labels
            }

            output = model(model_input)

            # Láº¥y output preds
            if isinstance(output, dict):
                scores = output["preds"].cpu().numpy()
            else:
                scores = output.cpu().numpy()

            # Xá»­ lÃ½ tá»«ng sample trong batch
            for i, imp_id in enumerate(batch["impression_ids"]):
                valid_len = batch["cand_lens"][i]
                valid_scores = scores[i, :valid_len]  # Cáº¯t bá» pháº§n padding
                ranks = calculate_ranks(valid_scores)
                predictions.append((imp_id, ranks))

    # 4. Save
    write_submission(predictions, args.output)


if __name__ == "__main__":
    main()